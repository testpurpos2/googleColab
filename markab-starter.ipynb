{"cells":[{"cell_type":"markdown","id":"b62f7f4e","metadata":{"id":"b62f7f4e"},"source":["# Markab Challenge - starter notebook"]},{"cell_type":"code","execution_count":null,"id":"c0d2655d","metadata":{"id":"c0d2655d"},"outputs":[],"source":["### Add team name and model name here ###\n","team_name = 'Team_name' \n","model_name = 'model_name'"]},{"cell_type":"markdown","id":"e73cae6a","metadata":{"id":"e73cae6a"},"source":["## Introduction\n","    Througout the scientific community, a vast amount of information is contained within figures in papers, reports, and books. Without the raw data, this information can be lost altogether. We can increase our collective knowledge as a community if we develop a way to extract this information and convert it to a useful format for agregation and downstream analysis."]},{"cell_type":"markdown","id":"547b865f","metadata":{"id":"547b865f"},"source":["## Problem statement\n","    Data points\n","    \n","    The goal of this challenge is to be able to extract the data points from a plot into a datatable listed the xy coordinates and symbol. Symbols are recorded as a number in the order appearing on the legend. \n","    \n","    [(X, Y, Z), (X, Y, Z), ...]\n","    \n","    X = X coordinate\n","    Y = Y coordinate\n","    Z = Symbol (number - order on legend)\n","    \n","    Ex: [(25, 162, 1), (32, 62, 2), ...]"]},{"cell_type":"markdown","id":"db69b1aa","metadata":{"id":"db69b1aa"},"source":["## Data description\n","    1. Image files containing one graph per file.\n","    2. CSV file containing the image file name marker coordinates. These labels are to be used to train and test the model on the associated graphs."]},{"cell_type":"markdown","id":"318d4db3","metadata":{"id":"318d4db3"},"source":["## Shared imports"]},{"cell_type":"code","execution_count":null,"id":"5c61b798","metadata":{"id":"5c61b798"},"outputs":[],"source":["import os\n","import cv2\n","import json\n","import random as rnd\n","import copy\n","import re\n","import platform\n","import sys\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from glob import glob\n","from pprint import pprint\n","from sklearn import metrics"]},{"cell_type":"markdown","id":"a63ac6be","metadata":{"id":"a63ac6be"},"source":["## Dataset paths"]},{"cell_type":"code","execution_count":null,"id":"88b82bf2","metadata":{"id":"88b82bf2"},"outputs":[],"source":["DATA_ROOT = \"./../../../utilities-master-axis_detection_challenge/axis_detection_challenge/markab_challenge_dataset_test\" # Adjust this path to reflect where the data is stored on your personal computer\n","IMAGE_DATASET_PATH = f\"{DATA_ROOT}/images\"\n","LABELS_DATA_PATH = f\"{DATA_ROOT}/labels\" "]},{"cell_type":"code","execution_count":null,"id":"bd158836","metadata":{"id":"bd158836"},"outputs":[],"source":["PROCESSED_DATASET_PATH=f\"{DATA_ROOT}/processed\"\n","MODELS_ROOT_PATH=f\"./models\"\n","MODEL_PATH=f\"{MODELS_ROOT_PATH}/{model_name}\""]},{"cell_type":"markdown","id":"62b341e9","metadata":{"id":"62b341e9"},"source":["## Data file exploration"]},{"cell_type":"code","execution_count":null,"id":"97117ee4","metadata":{"id":"97117ee4"},"outputs":[],"source":[" def read_image_filenames(path):\n","    extensions = [\"*.png\"]\n","    image_filenames = []\n","    for ext in extensions:\n","        image_filenames.extend(glob(os.path.join(path, ext)))\n","    return image_filenames"]},{"cell_type":"code","execution_count":null,"id":"c0ccc588","metadata":{"id":"c0ccc588"},"outputs":[],"source":["image_filenames = read_image_filenames(IMAGE_DATASET_PATH) "]},{"cell_type":"code","execution_count":null,"id":"9bdba890","metadata":{"id":"9bdba890"},"outputs":[],"source":["pprint(image_filenames[0:5]) "]},{"cell_type":"code","execution_count":null,"id":"6d7a8f39","metadata":{"id":"6d7a8f39"},"outputs":[],"source":[" def read_label_filenames(path):\n","    extensions = [\"*.csv\"]\n","    label_filenames = []\n","    for ext in extensions:\n","        label_filenames.extend(glob(os.path.join(path, ext)))\n","    return label_filenames"]},{"cell_type":"code","execution_count":null,"id":"ab068997","metadata":{"id":"ab068997"},"outputs":[],"source":["label_filenames = read_label_filenames(LABELS_DATA_PATH) "]},{"cell_type":"code","execution_count":null,"id":"2dc7e75e","metadata":{"id":"2dc7e75e"},"outputs":[],"source":["pprint(label_filenames) "]},{"cell_type":"markdown","id":"3ef44f63","metadata":{"id":"3ef44f63"},"source":["## Import data labels"]},{"cell_type":"code","execution_count":null,"id":"1166a016","metadata":{"id":"1166a016"},"outputs":[],"source":["def import_labels (label):\n","    labels = pd.read_csv(label[0])\n","    return labels\n"]},{"cell_type":"code","execution_count":null,"id":"8c7abbd2","metadata":{"id":"8c7abbd2"},"outputs":[],"source":["labels = import_labels(label_filenames)"]},{"cell_type":"markdown","id":"573f2933","metadata":{"id":"573f2933"},"source":["## Preview data\n","    Here are the first 5 examples of the labels. Each row corresponds to a different graph."]},{"cell_type":"code","execution_count":null,"id":"6b6db356","metadata":{"id":"6b6db356"},"outputs":[],"source":["pprint(labels.head())"]},{"cell_type":"markdown","id":"8c93f94c","metadata":{"id":"8c93f94c"},"source":["## Image import"]},{"cell_type":"code","execution_count":null,"id":"53253739","metadata":{"id":"53253739"},"outputs":[],"source":["def read_image(image_filenames):\n","    image = cv2.imread(image_filenames) \n","    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB) "]},{"cell_type":"markdown","id":"2df003f5","metadata":{"id":"2df003f5"},"source":["## Preview selected images"]},{"cell_type":"code","execution_count":null,"id":"78f0bb50","metadata":{"id":"78f0bb50"},"outputs":[],"source":["def preview_images(image_filenames):\n","    figsize=(20,20)\n","    nrows = len(image_filenames)\n","    ncols = 1\n","    fig, (axes) = plt.subplots(nrows, ncols, figsize=figsize, dpi=120)\n","\n","    for i in range(nrows):\n","        img_filename = image_filenames[i]\n","        image = read_image(img_filename)\n","\n","        axis = axes[i] if nrows > 1 else axes\n","        axis.imshow(image)\n","\n","        title = os.path.basename(img_filename)\n","        axis.set_title(title)\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"6e8b9e2a","metadata":{"id":"6e8b9e2a"},"outputs":[],"source":["PREVIEW_IMAGES_COUNT=5\n","rnd.seed(101)\n","preview_image_filenames=rnd.sample(image_filenames, k=PREVIEW_IMAGES_COUNT)\n","pprint(preview_image_filenames)"]},{"cell_type":"markdown","id":"8f6b4b08","metadata":{"id":"8f6b4b08"},"source":["One way to tackle this problem is to consider the coordinates of the image elements. Here are the first 5 graphs as an example. Each graph is saved as separate png file."]},{"cell_type":"code","execution_count":null,"id":"59065e78","metadata":{"id":"59065e78"},"outputs":[],"source":["preview_images(preview_image_filenames) "]},{"cell_type":"markdown","id":"cff1b3ed","metadata":{"id":"cff1b3ed"},"source":["## Potential pipeline code\n","    The following code can be used to create your model pipeline. These functions outline suggested steps to help create the model. These functions are suggestions and you may change or edit as you see fit to create the desired functionality.\n"]},{"cell_type":"markdown","id":"a4153683","metadata":{"id":"a4153683"},"source":["## Data processing"]},{"cell_type":"code","execution_count":null,"id":"62caae70","metadata":{"id":"62caae70"},"outputs":[],"source":[" def process_data(image_dataset_path, PROCESSED_DATASET_PATH):\n","    \"\"\"\n","    Includes splitting, scaling, or extracting features from raw source images, which can then be used to train the model.    \n","    \"\"\"\n","    ### PUT YOUR CODE HERE ###\n","    \n","    pass"]},{"cell_type":"markdown","id":"c513769c","metadata":{"id":"c513769c"},"source":["## Dataset split"]},{"cell_type":"code","execution_count":null,"id":"b3274e38","metadata":{"id":"b3274e38"},"outputs":[],"source":["def split_dataset(PROCESSED_DATASET_PATH, labels):\n","    \"\"\"\n","    Split dataset files into train and test datasets.\n","    Depending on your method of data processing, model training, and model testing, we recommend a method that doesn't copy/move images.\n","    Instead, it returns lists of image filenames per each dataset. Modify subsequent code to match your method.\n","    \"\"\"    \n","    train_image_filenames = []\n","    train_labels = []\n","    test_image_filenames = []\n","    test_labels = []\n","    \n","    ### PUT YOUR CODE HERE ###\n","    \n","    return train_image_filenames, train_labels, test_image_filenames, test_labels"]},{"cell_type":"markdown","id":"5fc6f297","metadata":{"id":"5fc6f297"},"source":["## Model train"]},{"cell_type":"code","execution_count":null,"id":"68421c1e","metadata":{"id":"68421c1e"},"outputs":[],"source":[" def train_model(train_image_filenames, train_labels, MODEL_PATH):\n","        \n","    \"\"\"\n","    Train your model on provided graphs and labels.\n","    \"\"\"\n","        \n","    ### PUT YOUR CODE HERE ###\n","    \n","    pass"]},{"cell_type":"markdown","id":"99a48c9a","metadata":{"id":"99a48c9a"},"source":["## Model test"]},{"cell_type":"code","execution_count":null,"id":"f89bb692","metadata":{"id":"f89bb692"},"outputs":[],"source":["def test_model(test_image_filenames, test_labels,  MODEL_PATH):\n","\n","    ### PUT YOUR CODE HERE ###\n","    \n","    \"\"\"\n","    Test your model's performance here on the split provided data. It may be helpful to define some metrics to evaluate the model's performance. \n","    Note: submissions will be evaluated based on root mean squared error (RMSE) of the predictions and key.\n","    \"\"\"\n","\n","\n","    metrics = {}\n","    \n","    return metrics"]},{"cell_type":"markdown","id":"88946be5","metadata":{"id":"88946be5"},"source":["## Model inference"]},{"cell_type":"code","execution_count":null,"id":"d0202b37","metadata":{"id":"d0202b37"},"outputs":[],"source":["def run_inference(image_filenames, MODEL_PATH):\n","    \n","    \"\"\"\n","    Add functions defined above to run inference on unlabeled data. This function will be used to for the final submission of the notebook and evaluation. \n","    The function should return the predictions_sample_name and predicted_marker_coordinates.\n","    \n","    Currently, arguments include the model path and image filenames. Please edit the inputs in the submission inference pipeline below if you utilize another method.\n","    \"\"\"\n","\n","    ### PUT YOUR CODE HERE ####\n","    predictions_sample_name = []\n","    predicted_marker_coordinates = []\n","    \n","    \n","    ### Remove and add your model results here ###\n","    predictions_sample_name = labels.sample_name\n","    predicted_marker_coordinates = labels.marker_coordinates\n","    \n","    return predictions_sample_name, predicted_marker_coordinates\n","    "]},{"cell_type":"code","execution_count":null,"id":"b906f4dd","metadata":{"id":"b906f4dd"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9a290a9d","metadata":{"id":"9a290a9d"},"source":["## Submission inference pipeline"]},{"cell_type":"markdown","id":"b3cc2d1d","metadata":{"id":"b3cc2d1d"},"source":["    Model generated predicted_marker_coordinates will be compared to known values. Results will be evaluated based on the inference time and root mean square error (RMSE) of the model predictions. If you modified the inputs/outputs of previously listed functions, correct the following pipeline so it can handle images unknown to the user. \n","    \n","    The function needs to produce a CSV file containing sample_name and marker_coordinates.\n","    \n","    The pip freeze print can be used to help make the environment requirements file (requirements.txt)."]},{"cell_type":"code","execution_count":null,"id":"2213c2b0","metadata":{"id":"2213c2b0"},"outputs":[],"source":["from time import perf_counter"]},{"cell_type":"code","execution_count":null,"id":"37146d37","metadata":{"id":"37146d37"},"outputs":[],"source":["TEST_DATA_ROOT = \"./test_dataset\"\n","TEST_IMAGE_DATASET_PATH = f\"{TEST_DATA_ROOT}/images\"\n","TEST_LABELS_DATA_PATH = f\"{TEST_DATA_ROOT}/labels\"\n","TEST_INFERENCE_RESULTS_PATH = f\"{TEST_DATA_ROOT}/inference_results\""]},{"cell_type":"code","execution_count":null,"id":"0d7acdea","metadata":{"id":"0d7acdea"},"outputs":[],"source":[" def run_inference_pipeline(TEST_IMAGE_DATASET_PATH, TEST_INFERENCE_RESULTS_PATH, PROCESSED_DATASET_PATH, MODEL_PATH):\n","    \n","    print(\"Runing inference with parameters:\")\n","    print(f\"* OS                          : {platform.system()}, {platform.release()}\")\n","    python_version = str(sys.version).replace('\\n', ' ')\n","    print(f\"* Python version              : {python_version}\")\n","    print(\"\\n-- pip freeze start ---\")\n","    !pip freeze\n","    print(\"-- pip freeze end ---\")\n","\n","    os.makedirs(TEST_INFERENCE_RESULTS_PATH, exist_ok=True)\n","    \n","    image_filenames = read_image_filenames(TEST_IMAGE_DATASET_PATH)\n","           \n","    ts_start = perf_counter()\n","    \n","    process_data(TEST_IMAGE_DATASET_PATH, PROCESSED_DATASET_PATH)\n","    \n","    ts_after_processing = perf_counter()\n","\n","    predictions_sample_name, predicted_marker_coordinates = run_inference(image_filenames, MODEL_PATH) \n","    \n","    ts_after_test = perf_counter()\n","    \n","    Processing_time_s = ts_after_processing-ts_start\n","    Inference_time_s = ts_after_test-ts_after_processing\n","    \n","    print(f\"Processing time: {ts_after_processing-ts_start:.2f} sec.\")\n","    print(f\"Inference time: {ts_after_test-ts_after_processing:.2f} sec.\")\n","    \n","    \n","    inference_results = {'sample_name': predictions_sample_name,\n","                        'marker_coordinates': predicted_marker_coordinates}\n","    inference_results_df = pd.DataFrame(inference_results)\n","        \n","    inference_results_df.to_csv(f\"{TEST_INFERENCE_RESULTS_PATH}/{team_name}_{model_name}_results.csv\", index = False)\n","    \n","    print(inference_results_df)\n","\n","    print(f\"The submission file   : {TEST_INFERENCE_RESULTS_PATH}/{team_name}_{model_name}_results.csv\")\n","    \n"]},{"cell_type":"code","execution_count":null,"id":"594cd15d","metadata":{"id":"594cd15d"},"outputs":[],"source":[" run_inference_pipeline(\n","    TEST_IMAGE_DATASET_PATH,     \n","    TEST_INFERENCE_RESULTS_PATH, \n","    PROCESSED_DATASET_PATH, \n","    MODEL_PATH)"]},{"cell_type":"markdown","id":"56cd969c","metadata":{"id":"56cd969c"},"source":["## Submission"]},{"cell_type":"markdown","id":"f3a3114d","metadata":{"id":"f3a3114d"},"source":["Upload the inference results CSV file under the challenge on http://xeek.ai/ to score your model and update the leaderboard. Finalist will be invited to submit their notebook for final review and scoring."]},{"cell_type":"code","execution_count":null,"id":"930bc520","metadata":{"id":"930bc520"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b40bde37","metadata":{"id":"b40bde37"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"conda_python3","language":"python","name":"conda_python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}